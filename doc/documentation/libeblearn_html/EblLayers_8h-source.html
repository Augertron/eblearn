<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
<title>libeblearn: /home/pierre/eblearn-trunk/libeblearn/include/EblLayers.h Source File</title>
<link href="doxygen.css" rel="stylesheet" type="text/css">
<link href="tabs.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.5.6 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul>
      <li><a href="main.html"><span>Main&nbsp;Page</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li><a href="examples.html"><span>Examples</span></a></li>
    </ul>
  </div>
<h1>/home/pierre/eblearn-trunk/libeblearn/include/EblLayers.h</h1><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 <span class="comment">/***************************************************************************</span>
<a name="l00002"></a>00002 <span class="comment"> *   Copyright (C) 2008 by Yann LeCun and Pierre Sermanet *</span>
<a name="l00003"></a>00003 <span class="comment"> *   yann@cs.nyu.edu, pierre.sermanet@gmail.com *</span>
<a name="l00004"></a>00004 <span class="comment"> *</span>
<a name="l00005"></a>00005 <span class="comment"> * Redistribution and use in source and binary forms, with or without</span>
<a name="l00006"></a>00006 <span class="comment"> * modification, are permitted provided that the following conditions are met:</span>
<a name="l00007"></a>00007 <span class="comment"> *     * Redistributions of source code must retain the above copyright</span>
<a name="l00008"></a>00008 <span class="comment"> *       notice, this list of conditions and the following disclaimer.</span>
<a name="l00009"></a>00009 <span class="comment"> *     * Redistributions in binary form must reproduce the above copyright</span>
<a name="l00010"></a>00010 <span class="comment"> *       notice, this list of conditions and the following disclaimer in the</span>
<a name="l00011"></a>00011 <span class="comment"> *       documentation and/or other materials provided with the distribution.</span>
<a name="l00012"></a>00012 <span class="comment"> *     * Redistribution under a license not approved by the Open Source</span>
<a name="l00013"></a>00013 <span class="comment"> *       Initiative (http://www.opensource.org) must display the</span>
<a name="l00014"></a>00014 <span class="comment"> *       following acknowledgement in all advertising material:</span>
<a name="l00015"></a>00015 <span class="comment"> *        This product includes software developed at the Courant</span>
<a name="l00016"></a>00016 <span class="comment"> *        Institute of Mathematical Sciences (http://cims.nyu.edu).</span>
<a name="l00017"></a>00017 <span class="comment"> *     * The names of the authors may not be used to endorse or promote products</span>
<a name="l00018"></a>00018 <span class="comment"> *       derived from this software without specific prior written permission.</span>
<a name="l00019"></a>00019 <span class="comment"> *</span>
<a name="l00020"></a>00020 <span class="comment"> * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED</span>
<a name="l00021"></a>00021 <span class="comment"> * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED</span>
<a name="l00022"></a>00022 <span class="comment"> * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE</span>
<a name="l00023"></a>00023 <span class="comment"> * DISCLAIMED. IN NO EVENT SHALL ThE AUTHORS BE LIABLE FOR ANY</span>
<a name="l00024"></a>00024 <span class="comment"> * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES</span>
<a name="l00025"></a>00025 <span class="comment"> * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;</span>
<a name="l00026"></a>00026 <span class="comment"> * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND</span>
<a name="l00027"></a>00027 <span class="comment"> * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT</span>
<a name="l00028"></a>00028 <span class="comment"> * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS</span>
<a name="l00029"></a>00029 <span class="comment"> * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</span>
<a name="l00030"></a>00030 <span class="comment"> ***************************************************************************/</span>
<a name="l00031"></a>00031 
<a name="l00032"></a>00032 <span class="preprocessor">#ifndef EBLLAYERS_H_</span>
<a name="l00033"></a>00033 <span class="preprocessor"></span><span class="preprocessor">#define EBLLAYERS_H_</span>
<a name="l00034"></a>00034 <span class="preprocessor"></span>
<a name="l00035"></a>00035 <span class="preprocessor">#include "Defines.h"</span>
<a name="l00036"></a>00036 <span class="preprocessor">#include "Idx.h"</span>
<a name="l00037"></a>00037 <span class="preprocessor">#include "Blas.h"</span>
<a name="l00038"></a>00038 <span class="preprocessor">#include "EblStates.h"</span>
<a name="l00039"></a>00039 <span class="preprocessor">#include "EblBasic.h"</span>
<a name="l00040"></a>00040 <span class="preprocessor">#include "EblArch.h"</span>
<a name="l00041"></a>00041 <span class="preprocessor">#include "EblNonLinearity.h"</span>
<a name="l00042"></a>00042 
<a name="l00043"></a>00043 <span class="keyword">namespace </span>ebl {
<a name="l00044"></a>00044 
<a name="l00047"></a><a class="code" href="classebl_1_1nn__layer__full.html">00047</a>   <span class="keyword">class </span><a class="code" href="classebl_1_1nn__layer__full.html">nn_layer_full</a>: <span class="keyword">public</span> <a class="code" href="classebl_1_1module__1__1.html" title="abstract class for a module with one input and one output.">module_1_1</a>&lt;state_idx, state_idx&gt; {
<a name="l00048"></a>00048   <span class="keyword">public</span>:
<a name="l00049"></a><a class="code" href="classebl_1_1nn__layer__full.html#de098f406ed30d9e14740a7855f66c69">00049</a>     linear_module_replicable     <a class="code" href="classebl_1_1nn__layer__full.html#de098f406ed30d9e14740a7855f66c69" title="linear module for weight matrix">linear</a>;  
<a name="l00050"></a><a class="code" href="classebl_1_1nn__layer__full.html#6dc39235120ef743bf53cc52758c19c4">00050</a>     <a class="code" href="classebl_1_1addc__module.html">addc_module</a>                  <a class="code" href="classebl_1_1nn__layer__full.html#6dc39235120ef743bf53cc52758c19c4" title="bias vector">adder</a>;   
<a name="l00051"></a><a class="code" href="classebl_1_1nn__layer__full.html#97a8d6ffa303175b4700e56667a82c63">00051</a>     <a class="code" href="classebl_1_1tanh__module.html" title="a slab of tanh">tanh_module</a>                  <a class="code" href="classebl_1_1nn__layer__full.html#97a8d6ffa303175b4700e56667a82c63" title="the non-linear function">sigmoid</a>; 
<a name="l00052"></a><a class="code" href="classebl_1_1nn__layer__full.html#68d8a0d1c47320a3154a273a6340e104">00052</a>     <a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a>                   *<a class="code" href="classebl_1_1nn__layer__full.html#68d8a0d1c47320a3154a273a6340e104" title="weighted sum">sum</a>;     
<a name="l00053"></a>00053 
<a name="l00057"></a>00057     <a class="code" href="classebl_1_1nn__layer__full.html#9237b97a4e55d4b4a0f736123dcf6dea">nn_layer_full</a>(<a class="code" href="classebl_1_1parameter.html">parameter</a> &amp;p, intg indim0, intg noutputs);
<a name="l00058"></a>00058     <span class="keyword">virtual</span> ~<a class="code" href="classebl_1_1nn__layer__full.html">nn_layer_full</a>();
<a name="l00060"></a>00060     <span class="keywordtype">void</span> <a class="code" href="classebl_1_1nn__layer__full.html#f3092b83af13d0dd9b5184f6845d7adf" title="fprop from in to out">fprop</a>(<a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;in, <a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;out);
<a name="l00062"></a>00062     <span class="keywordtype">void</span> <a class="code" href="classebl_1_1nn__layer__full.html#4d799cd9b7e249708529ac23b33cf790" title="bprop">bprop</a>(<a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;in, <a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;out);
<a name="l00064"></a>00064     <span class="keywordtype">void</span> <a class="code" href="classebl_1_1nn__layer__full.html#dbe598cdff579e71d7a7092f785176f5" title="bbprop">bbprop</a>(<a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;in, <a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;out);
<a name="l00066"></a>00066     <span class="keywordtype">void</span> <a class="code" href="classebl_1_1nn__layer__full.html#6f827373bec69562711a1707825b9fa7" title="initialize the weights to random values">forget</a>(forget_param_linear &amp;fp);
<a name="l00067"></a>00067   };
<a name="l00068"></a>00068 
<a name="l00071"></a><a class="code" href="classebl_1_1nn__layer__convolution.html">00071</a>   <span class="keyword">class </span><a class="code" href="classebl_1_1nn__layer__convolution.html">nn_layer_convolution</a>: <span class="keyword">public</span> <a class="code" href="classebl_1_1module__1__1.html" title="abstract class for a module with one input and one output.">module_1_1</a>&lt;state_idx, state_idx&gt; {
<a name="l00072"></a>00072   <span class="keyword">public</span>:
<a name="l00074"></a><a class="code" href="classebl_1_1nn__layer__convolution.html#b5ffc9f3ddf922691b9c001245ed1792">00074</a>     convolution_module_2D_replicable <a class="code" href="classebl_1_1nn__layer__convolution.html#b5ffc9f3ddf922691b9c001245ed1792" title="&amp;lt; convolution module">convol</a>;
<a name="l00075"></a><a class="code" href="classebl_1_1nn__layer__convolution.html#9893379970ddc8342d4aa1c8fd4f66b5">00075</a>     <a class="code" href="classebl_1_1addc__module.html">addc_module</a>           <a class="code" href="classebl_1_1nn__layer__convolution.html#9893379970ddc8342d4aa1c8fd4f66b5" title="bias vector">adder</a>;   
<a name="l00076"></a><a class="code" href="classebl_1_1nn__layer__convolution.html#f61ec64dd69846ebb8dae8b774c20acc">00076</a>     <a class="code" href="classebl_1_1tanh__module.html" title="a slab of tanh">tanh_module</a>           <a class="code" href="classebl_1_1nn__layer__convolution.html#f61ec64dd69846ebb8dae8b774c20acc" title="the non-linear function">sigmoid</a>; 
<a name="l00077"></a><a class="code" href="classebl_1_1nn__layer__convolution.html#0cc15e870bea22b103689eb03cd52638">00077</a>     <a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a>             *<a class="code" href="classebl_1_1nn__layer__convolution.html#0cc15e870bea22b103689eb03cd52638" title="convolution result">sum</a>;     
<a name="l00078"></a>00078 
<a name="l00082"></a>00082     <a class="code" href="classebl_1_1nn__layer__convolution.html#d5ffa4eafdf4dee8d8a613c16a8e7d6f">nn_layer_convolution</a>(<a class="code" href="classebl_1_1parameter.html">parameter</a> &amp;p, intg kerneli, intg kernelj, 
<a name="l00083"></a>00083                          intg ri, intg rj, Idx&lt;intg&gt; &amp;tbl, intg thick);
<a name="l00084"></a>00084     <span class="keyword">virtual</span> ~<a class="code" href="classebl_1_1nn__layer__convolution.html">nn_layer_convolution</a>();
<a name="l00086"></a>00086     <span class="keywordtype">void</span> <a class="code" href="classebl_1_1nn__layer__convolution.html#788cd80bd590de83029e5b54e7f40769" title="fprop from in to out">fprop</a>(<a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;in, <a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;out);
<a name="l00088"></a>00088     <span class="keywordtype">void</span> <a class="code" href="classebl_1_1nn__layer__convolution.html#e5861abb7f0773fd505bbc86a202fe35" title="bprop">bprop</a>(<a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;in, <a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;out);
<a name="l00090"></a>00090     <span class="keywordtype">void</span> <a class="code" href="classebl_1_1nn__layer__convolution.html#910b3e781901ce80b45eb48552299024" title="bbprop">bbprop</a>(<a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;in, <a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;out);
<a name="l00092"></a>00092     <span class="keywordtype">void</span> <a class="code" href="classebl_1_1nn__layer__convolution.html#b971bc529a7e7ff6e7d610d38b640072" title="initialize the weights to random values">forget</a>(forget_param_linear &amp;fp);
<a name="l00093"></a>00093   };
<a name="l00094"></a>00094 
<a name="l00097"></a><a class="code" href="classebl_1_1nn__layer__subsampling.html">00097</a>   <span class="keyword">class </span><a class="code" href="classebl_1_1nn__layer__subsampling.html">nn_layer_subsampling</a>: <span class="keyword">public</span> <a class="code" href="classebl_1_1module__1__1.html" title="abstract class for a module with one input and one output.">module_1_1</a>&lt;state_idx, state_idx&gt; {
<a name="l00098"></a>00098   <span class="keyword">public</span>:
<a name="l00099"></a><a class="code" href="classebl_1_1nn__layer__subsampling.html#13bf854cca8e30d6b1035979ee2b44df">00099</a>     subsampling_module_2D_replicable <a class="code" href="classebl_1_1nn__layer__subsampling.html#13bf854cca8e30d6b1035979ee2b44df" title="subsampling module">subsampler</a>; 
<a name="l00100"></a><a class="code" href="classebl_1_1nn__layer__subsampling.html#0499f376d8498bedb1cfac510edfaf34">00100</a>     <a class="code" href="classebl_1_1addc__module.html">addc_module</a>           <a class="code" href="classebl_1_1nn__layer__subsampling.html#0499f376d8498bedb1cfac510edfaf34" title="bias vector">adder</a>;      
<a name="l00101"></a><a class="code" href="classebl_1_1nn__layer__subsampling.html#47bce23c97c6323ee6b8676d1ba2d4b6">00101</a>     <a class="code" href="classebl_1_1tanh__module.html" title="a slab of tanh">tanh_module</a>           <a class="code" href="classebl_1_1nn__layer__subsampling.html#47bce23c97c6323ee6b8676d1ba2d4b6" title="the non-linear function">sigmoid</a>;    
<a name="l00102"></a><a class="code" href="classebl_1_1nn__layer__subsampling.html#ebf5670fc588f122da79f46f46ab07a6">00102</a>     <a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a>             *<a class="code" href="classebl_1_1nn__layer__subsampling.html#ebf5670fc588f122da79f46f46ab07a6" title="subsampling result">sum</a>;        
<a name="l00103"></a>00103 
<a name="l00107"></a>00107     <a class="code" href="classebl_1_1nn__layer__subsampling.html#7b6e5d43616dd7cf354efa592eaa5136">nn_layer_subsampling</a>(<a class="code" href="classebl_1_1parameter.html">parameter</a> &amp;p, intg stridei, intg stridej,
<a name="l00108"></a>00108                                              intg subi, intg subj, 
<a name="l00109"></a>00109                                              intg thick);
<a name="l00110"></a>00110     <span class="keyword">virtual</span> ~<a class="code" href="classebl_1_1nn__layer__subsampling.html">nn_layer_subsampling</a>();
<a name="l00112"></a>00112     <span class="keywordtype">void</span> <a class="code" href="classebl_1_1nn__layer__subsampling.html#9af539fce91c8c334d43de2e3c7bdc13" title="fprop from in to out">fprop</a>(<a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;in, <a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;out);
<a name="l00114"></a>00114     <span class="keywordtype">void</span> <a class="code" href="classebl_1_1nn__layer__subsampling.html#2a654e9db7685316c87d68e26f8c690e" title="bprop">bprop</a>(<a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;in, <a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;out);
<a name="l00116"></a>00116     <span class="keywordtype">void</span> <a class="code" href="classebl_1_1nn__layer__subsampling.html#2e6abc741417c7f98fa983a0b44e8ea7" title="bbprop">bbprop</a>(<a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;in, <a class="code" href="classebl_1_1state__idx.html" title="class that stores a vector/tensor state">state_idx</a> &amp;out);
<a name="l00118"></a>00118     <span class="keywordtype">void</span> <a class="code" href="classebl_1_1nn__layer__subsampling.html#d4a2e315406de6cc6e2529b07d8f42b5" title="initialize the weights to random values">forget</a>(forget_param_linear &amp;fp);
<a name="l00119"></a>00119   };
<a name="l00120"></a>00120 
<a name="l00121"></a>00121 } <span class="comment">// namespace ebl {</span>
<a name="l00122"></a>00122 
<a name="l00123"></a>00123 <span class="preprocessor">#endif </span><span class="comment">/* EBLLAYERS_H_ */</span>
</pre></div></div>
<hr size="1"><address style="text-align: right;"><small>Generated on Thu Feb 26 18:53:41 2009 for libeblearn by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border="0"></a> 1.5.6 </small></address>
</body>
</html>
